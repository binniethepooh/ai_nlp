{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 어텐션(Attention)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 맥락 벡터 : 단어 벡터에 가중치를 를 곱하여 합한 가중합을 구한 벡터\n",
    "단어를 선택하는 작업은 미분 불가하므로 모든 것을 선택하고 단어의 중요도를 가중치로 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hs:\n",
      " [[-1.74976547  0.3426804   1.1530358  -0.25243604]\n",
      " [ 0.98132079  0.51421884  0.22117967 -1.07004333]\n",
      " [-0.18949583  0.25500144 -0.45802699  0.43516349]\n",
      " [-0.58359505  0.81684707  0.67272081 -0.10441114]\n",
      " [-0.53128038  1.02973269 -0.43813562 -1.11831825]]\n",
      "hs0: [-1.74976547  0.3426804   1.1530358  -0.25243604]\n",
      "a:\n",
      " [0.8  0.1  0.03 0.05 0.02]\n",
      "ar:\n",
      " [[0.8  0.8  0.8  0.8 ]\n",
      " [0.1  0.1  0.1  0.1 ]\n",
      " [0.03 0.03 0.03 0.03]\n",
      " [0.05 0.05 0.05 0.05]\n",
      " [0.02 0.02 0.02 0.02]] (5, 4)\n",
      "t:\n",
      " [[-1.39981238  0.27414432  0.92242864 -0.20194883]\n",
      " [ 0.09813208  0.05142188  0.02211797 -0.10700433]\n",
      " [-0.00568487  0.00765004 -0.01374081  0.0130549 ]\n",
      " [-0.02917975  0.04084235  0.03363604 -0.00522056]\n",
      " [-0.01062561  0.02059465 -0.00876271 -0.02236636]] (5, 4)\n",
      "ar:\n",
      " [[0.8 ]\n",
      " [0.1 ]\n",
      " [0.03]\n",
      " [0.05]\n",
      " [0.02]] (5, 1)\n",
      "t:\n",
      " [[-1.39981238  0.27414432  0.92242864 -0.20194883]\n",
      " [ 0.09813208  0.05142188  0.02211797 -0.10700433]\n",
      " [-0.00568487  0.00765004 -0.01374081  0.0130549 ]\n",
      " [-0.02917975  0.04084235  0.03363604 -0.00522056]\n",
      " [-0.01062561  0.02059465 -0.00876271 -0.02236636]] (5, 4)\n",
      "c:    [-1.34717053  0.39465326  0.95567913 -0.32348518]\n",
      "hs0:  [-1.74976547  0.3426804   1.1530358  -0.25243604]\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(100)\n",
    "\n",
    "T,H = 5,4   # T : 시계열의 길이, H : Hidden size\n",
    "hs = np.random.randn(T,H)  # (5,4)\n",
    "print('hs:\\n',hs)\n",
    "print('hs0:',hs[0])\n",
    "\n",
    "a  = np.array([0.8, 0.1, 0.03, 0.05, 0.02]) # 가중치\n",
    "a.sum()  # 1.0\n",
    "print('a:\\n',a)\n",
    "\n",
    "# (1) repeat() 함수 사용\n",
    "ar = a.reshape(T,1).repeat(4,axis=1)\n",
    "print('ar:\\n',ar, ar.shape)\n",
    "\n",
    "t = hs * ar\n",
    "print('t:\\n',t,t.shape)\n",
    "\n",
    "# (2) Numpy 브로드캐스팅 사용, 1번과 결과 동일 \n",
    "ar = a.reshape(T,1)  # (5,1)로 2차원으로 shape을 바꿈\n",
    "print('ar:\\n',ar, ar.shape)\n",
    "\n",
    "t = hs * ar           # (5,4) * (5,1) : 브로드캐스팅 적용, , 단어벡터에 가중치를 곱함\n",
    "print('t:\\n',t,t.shape)\n",
    "\n",
    "c = np.sum(t, axis=0)  # 수직 방향으로 합 , 가중합, 맥락 벡터\n",
    "print('c:   ',c)\n",
    "print('hs0: ',hs[0])\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      " [[-1.74976547  0.3426804   1.1530358  -0.25243604  0.98132079]\n",
      " [ 0.51421884  0.22117967 -1.07004333 -0.18949583  0.25500144]\n",
      " [-0.45802699  0.43516349 -0.58359505  0.81684707  0.67272081]\n",
      " [-0.10441114 -0.53128038  1.02973269 -0.43813562 -1.11831825]\n",
      " [ 1.61898166  1.54160517 -0.25187914 -0.84243574  0.18451869]\n",
      " [ 0.9370822   0.73100034  1.36155613 -0.32623806  0.05567601]\n",
      " [ 0.22239961 -1.443217   -0.75635231  0.81645401  0.75044476]\n",
      " [-0.45594693  1.18962227 -1.69061683 -1.35639905 -1.23243451]\n",
      " [-0.54443916 -0.66817174  0.00731456 -0.61293874  1.29974807]\n",
      " [-1.73309562 -0.9833101   0.35750775 -1.6135785   1.47071387]]\n",
      "ar:\n",
      " [[[-1.74976547 -1.74976547 -1.74976547 -1.74976547]\n",
      "  [ 0.3426804   0.3426804   0.3426804   0.3426804 ]\n",
      "  [ 1.1530358   1.1530358   1.1530358   1.1530358 ]\n",
      "  [-0.25243604 -0.25243604 -0.25243604 -0.25243604]\n",
      "  [ 0.98132079  0.98132079  0.98132079  0.98132079]]\n",
      "\n",
      " [[ 0.51421884  0.51421884  0.51421884  0.51421884]\n",
      "  [ 0.22117967  0.22117967  0.22117967  0.22117967]\n",
      "  [-1.07004333 -1.07004333 -1.07004333 -1.07004333]\n",
      "  [-0.18949583 -0.18949583 -0.18949583 -0.18949583]\n",
      "  [ 0.25500144  0.25500144  0.25500144  0.25500144]]\n",
      "\n",
      " [[-0.45802699 -0.45802699 -0.45802699 -0.45802699]\n",
      "  [ 0.43516349  0.43516349  0.43516349  0.43516349]\n",
      "  [-0.58359505 -0.58359505 -0.58359505 -0.58359505]\n",
      "  [ 0.81684707  0.81684707  0.81684707  0.81684707]\n",
      "  [ 0.67272081  0.67272081  0.67272081  0.67272081]]\n",
      "\n",
      " [[-0.10441114 -0.10441114 -0.10441114 -0.10441114]\n",
      "  [-0.53128038 -0.53128038 -0.53128038 -0.53128038]\n",
      "  [ 1.02973269  1.02973269  1.02973269  1.02973269]\n",
      "  [-0.43813562 -0.43813562 -0.43813562 -0.43813562]\n",
      "  [-1.11831825 -1.11831825 -1.11831825 -1.11831825]]\n",
      "\n",
      " [[ 1.61898166  1.61898166  1.61898166  1.61898166]\n",
      "  [ 1.54160517  1.54160517  1.54160517  1.54160517]\n",
      "  [-0.25187914 -0.25187914 -0.25187914 -0.25187914]\n",
      "  [-0.84243574 -0.84243574 -0.84243574 -0.84243574]\n",
      "  [ 0.18451869  0.18451869  0.18451869  0.18451869]]\n",
      "\n",
      " [[ 0.9370822   0.9370822   0.9370822   0.9370822 ]\n",
      "  [ 0.73100034  0.73100034  0.73100034  0.73100034]\n",
      "  [ 1.36155613  1.36155613  1.36155613  1.36155613]\n",
      "  [-0.32623806 -0.32623806 -0.32623806 -0.32623806]\n",
      "  [ 0.05567601  0.05567601  0.05567601  0.05567601]]\n",
      "\n",
      " [[ 0.22239961  0.22239961  0.22239961  0.22239961]\n",
      "  [-1.443217   -1.443217   -1.443217   -1.443217  ]\n",
      "  [-0.75635231 -0.75635231 -0.75635231 -0.75635231]\n",
      "  [ 0.81645401  0.81645401  0.81645401  0.81645401]\n",
      "  [ 0.75044476  0.75044476  0.75044476  0.75044476]]\n",
      "\n",
      " [[-0.45594693 -0.45594693 -0.45594693 -0.45594693]\n",
      "  [ 1.18962227  1.18962227  1.18962227  1.18962227]\n",
      "  [-1.69061683 -1.69061683 -1.69061683 -1.69061683]\n",
      "  [-1.35639905 -1.35639905 -1.35639905 -1.35639905]\n",
      "  [-1.23243451 -1.23243451 -1.23243451 -1.23243451]]\n",
      "\n",
      " [[-0.54443916 -0.54443916 -0.54443916 -0.54443916]\n",
      "  [-0.66817174 -0.66817174 -0.66817174 -0.66817174]\n",
      "  [ 0.00731456  0.00731456  0.00731456  0.00731456]\n",
      "  [-0.61293874 -0.61293874 -0.61293874 -0.61293874]\n",
      "  [ 1.29974807  1.29974807  1.29974807  1.29974807]]\n",
      "\n",
      " [[-1.73309562 -1.73309562 -1.73309562 -1.73309562]\n",
      "  [-0.9833101  -0.9833101  -0.9833101  -0.9833101 ]\n",
      "  [ 0.35750775  0.35750775  0.35750775  0.35750775]\n",
      "  [-1.6135785  -1.6135785  -1.6135785  -1.6135785 ]\n",
      "  [ 1.47071387  1.47071387  1.47071387  1.47071387]]]\n",
      "(10, 5, 4)\n",
      "c:\n",
      " [[ 2.80542708  0.67492463 -3.06964038 -0.49429174]\n",
      " [ 1.66909252  0.35458585 -0.69390567  1.18438439]\n",
      " [ 0.40873493 -1.14219042  0.29743893  0.57340786]\n",
      " [ 1.32456655  0.84165295 -3.78716073  1.46092809]\n",
      " [ 0.86880452  2.39259227 -3.51633402  0.95428607]\n",
      " [-1.12067803 -1.99278502 -4.444337    0.584148  ]\n",
      " [-0.74776957  2.80149671 -0.98071568  0.88103137]\n",
      " [ 0.05516255  0.99666158 -5.88924593  3.22662741]\n",
      " [-0.76487492  1.66086252 -0.95792573 -2.75604623]\n",
      " [-2.20701717 -1.099727    0.44883028  3.93161299]]\n",
      "(10, 4)\n"
     ]
    }
   ],
   "source": [
    "# 3차원 배열의 가중합의 구현, 맥락 벡터\n",
    "np.random.seed(100)\n",
    "\n",
    "N, T, H = 10, 5, 4      # 면,행,열\n",
    "hs = np.random.randn(N, T, H)\n",
    "# print('hs:\\n',hs)\n",
    "\n",
    "np.random.seed(100)\n",
    "a  = np.random.randn(N, T)  # 가중치의 합이 1이 아닌 예임\n",
    "print('a:\\n',a)\n",
    "\n",
    "ar = a.reshape(N, T, 1).repeat(H, axis=2)  # 2번축(열)로 4번 반복\n",
    "print('ar:\\n',ar)\n",
    "\n",
    "t = hs * ar  # (10,5, 4)\n",
    "# print('t:\\n',t)\n",
    "print(t.shape)\n",
    "\n",
    "c = np.sum(t, axis=1)  # 1번 축(행)으로 합 \n",
    "print('c:\\n',c)\n",
    "print(c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중합 WeightSum 계층 구현 : 맥락벡터를 구하는 계층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중합을 구하는 class\n",
    "class WeightSum:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [],[]\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, hs, a):  # hs : (N,T,H)\n",
    "        N,T,H = hs.shape\n",
    "        \n",
    "        ar = a.reshape(N,T,1) # .repeat(H, axis=2)는 생략가능\n",
    "        t = hs * ar\n",
    "        c = np.sum(t, axis=1)  # (N,H)\n",
    "        \n",
    "        self.cache = (hs, ar)\n",
    "        return c\n",
    "    \n",
    "    def backward(self,dc) :\n",
    "        hs, ar = self.cache\n",
    "        N,T,H = hs.shape\n",
    "        \n",
    "        dt = dc.reshape(N,1,H).repeat(T,axis=1)   # sum의 역전파, 출력: (N,T,H)\n",
    "        dar = dt * hs       # (N,T,H)\n",
    "        dhs = dt * ar       # (N,T,H)\n",
    "        da = np.sum(dar, axis=2)    # repeat의 역전파, 출력 :(N,T)\n",
    "        \n",
    "        return dhs, da"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 가중치를 구하는 AttentionWeight 계층 구현: 각 단어의 가중치를 구하여 WeightSum 계층으로 전달한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn_layers.py에 아래 Softmax class추가\n",
    "# class Softmax:\n",
    "#     def __init__(self):\n",
    "#         self.params, self.grads = [], []\n",
    "#         self.out = None\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         self.out = softmax(x)\n",
    "#         return self.out\n",
    "\n",
    "#     def backward(self, dout):\n",
    "#         dx = self.out * dout\n",
    "#         sumdx = np.sum(dx, axis=1, keepdims=True)\n",
    "#         dx -= self.out * sumdx\n",
    "#         return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_layers import softmax, Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각단어의 가중치를 구하는 class\n",
    "class AttentionWeight:\n",
    "    def __init__(self):\n",
    "        self.params, self.grads = [],[]\n",
    "        self.softmax = Softmax()\n",
    "        self.cache = None\n",
    "        \n",
    "    def forward(self, hs, h) :  # hs: (N,T,H),  h : (N,H)\n",
    "        N,T,H = hs.shape\n",
    "        \n",
    "        hr = h.reshape(N,1,H) # .repeat(T,axis=1)는 생략가능\n",
    "        t = hs * hr           #  (N,T,H)\n",
    "        s = np.sum(t, axis=2) #  (N,T)\n",
    "        a = self.softmax.forward(s)  # (N,T)\n",
    "        \n",
    "        self.cache = (hs,hr)\n",
    "        return a\n",
    "    \n",
    "    def backward(self, da) :\n",
    "        hs,hr = self.cache\n",
    "        N,T,H = hs.shape\n",
    "        \n",
    "        ds = self.softmax.backward(da)    # (N,T)\n",
    "        dt = ds.reshape(N,T,1).repeat(H,axis=2)  # (N,T,H)\n",
    "        dhs = dt * hr              # (N,T,H)\n",
    "        dhr = dt * hs              # (N,T,H)\n",
    "        dh = np.sum(dhr, axis=1)   # (N,H)\n",
    "        \n",
    "        return dhs, dh     # (N,T,H) , (N,H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
